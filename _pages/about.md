---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a first-year MPhil in Data Science and Analysis (DSA) at the Hong Kong University of Science and Technology (Guangzhou), with [Professor Yuyu Luo](https://luoyuyu.vip/) and [Professor Nan Tang](https://nantang.github.io/) as my supervisors. Meanwhile, my second supervisor is [Professor Tongyi Zhang](https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page?id=98), who is also an Academician of the Chinese Academy of Sciences. Previously, I obtained my bachelor's degree from Nanjing University of Information Science and Technology in 2024. My research interests are Large Language Model(LLM) reasoning, post-training of LLMs, and how to use LLMs for more human-friendly visualization systems. Currently, my work is also devoted to exploring the application of post-training paradigms such as RL in the agent field.


# ğŸ”¥ News
- *2025.05*: &nbsp;ğŸ‰ğŸ‰ We proposed LiteCoT and corresponding series models Liter (Submitted to NeurIPS 2025).
- *2025.01*: &nbsp;ğŸ‰ğŸ‰ We proposed ChartFinder and ChartCards under the coorperation with HUAWEI (Submitted to SIGMOD2026 and NeurIPS 2025 respectively).
- *2025.01*: &nbsp;ğŸ‰ğŸ‰ We proposed AskChart, which is a chart understanding model designed on MoE architecture.
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ ChartInsights was accepted by EMNLP2024(Findings).
- *2024.08*: &nbsp;ğŸ‰ğŸ‰ I joined the DIAL LAB at HKUST(GZ) as a Mphil student, advised by Professor Yuyu Luo.

# ğŸ“ Publications 

<div class='paper-box'>
  <div class='paper-box-image'>
    <div> 
    <div class="badge">ARXIV</div>
    <img src='images/chartfinder.png' alt="sym" width="100%">
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights](https://www.arxiv.org/pdf/2505.10043)

**Yifan Wu**, Lutao Yan, Yizhang Zhu, Yinan Mei, Jiannan Wang, Nan Tang, Yuyu Luo

[**Paper**](https://www.arxiv.org/pdf/2505.10043) 
<strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div> 
    <div class="badge">ARXIV</div>
    <img src='images/askchart.png' alt="sym" width="100%">
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[ASKCHART: UNIVERSAL CHART UNDERSTANDING THROUGH TEXTUAL ENHANCEMENT](https://arxiv.org/abs/2412.19146)

Xudong Yang, **Yifan Wu**, Yizhang Zhu, Nan Tang, Yuyu Luo

[**Code**](https://github.com/Sootung/AskChart) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://arxiv.org/pdf/2412.19146) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>

<div class='paper-box'>
  <div class='paper-box-image'>
    <div> 
    <div class="badge">EMNLP 2024</div>
    <img src='images/chartinsights.png' alt="sym" width="100%">
    </div>
  </div>
<div class='paper-box-text' markdown="1">

[ChartInsights: Evaluating Multimodal Large Language Models for Low-Level Chart Question Answering](https://arxiv.org/abs/2405.07001)

**Yifan Wu**, Lutao Yan, Leixian Shen, Yunhai Wang, Nan Tang, Yuyu Luo

[**Home Page**](https://chartinsight.github.io/) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Code**](https://github.com/HKUSTDial/ChartInsights) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
[**Paper**](https://arxiv.org/abs/2405.07001) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
</div>
</div>





<!-- - [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020** -->

# ğŸ– Honors and Awards
- *2024.07* Excellent Graduation Thesis of Jiangsu Province 
- *2024.02* Win Finalist Award in Mathematical Contest in Modeling (MCM/ICM)
- *2023.07* Eligibility for government-sponsored study abroad to Canada (Sponsored by CSC)
- *2023.09* National Mathematical Contest of Modelling (First Prize in JiangSu Province)


# ğŸ“– Educations
- *2024.09 - 2026.07 (now)*, The Hong Kong University of Science and Technology (Guangzhou). 
- *2020.09 - 2024.06*, Nanjing University of Information Science and Technology. 

<!-- # ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# ğŸ’» Internships
- *2024.07 - 2024.09*, Research Intern in HUAWEI, BeiJing.
- *2024.02 - 2024.06*, Research Assistant in HKUST(Guangzhou), Guangzhou.
- *2023.07 - 2023.010*, Research Intern in University of Victoria, Canada.